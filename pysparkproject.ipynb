{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Science for Good - Text classification using PySpark ML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyspark in /home/mnegm/anaconda3/lib/python3.9/site-packages (3.3.1)\n",
      "Requirement already satisfied: py4j==0.10.9.5 in /home/mnegm/anaconda3/lib/python3.9/site-packages (from pyspark) (0.10.9.5)\n"
     ]
    }
   ],
   "source": [
    "# ipmortant libraries\n",
    "!#pip install pyspark\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/media/mnegm/Negmo's Files/Artificial intelligence/Negmo's workspace/Python/Pysparkpro/data/sample_submission.csv\n",
      "/media/mnegm/Negmo's Files/Artificial intelligence/Negmo's workspace/Python/Pysparkpro/data/test.csv\n",
      "/media/mnegm/Negmo's Files/Artificial intelligence/Negmo's workspace/Python/Pysparkpro/data/train.csv\n"
     ]
    }
   ],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk(\"/media/mnegm/Negmo's Files/Artificial intelligence/Negmo's workspace/Python/Pysparkpro/data\"):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import CountVectorizer,StringIndexer, RegexTokenizer,StopWordsRemover\n",
    "from pyspark.sql.functions import col, udf,regexp_replace,isnull\n",
    "from pyspark.sql.types import StringType,IntegerType\n",
    "from pyspark.ml.classification import NaiveBayes, RandomForestClassifier, LogisticRegression, DecisionTreeClassifier, GBTClassifier\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator, BinaryClassificationEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/12/20 23:17:02 WARN Utils: Your hostname, mnegm-Latitude-E7440 resolves to a loopback address: 127.0.1.1, but we couldn't find any external IP address!\n",
      "22/12/20 23:17:02 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/12/20 23:17:04 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "22/12/20 23:17:05 WARN MacAddressUtil: Failed to find a usable hardware address from the network interfaces; using random bytes: 31:30:2d:97:61:50:63:bc\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder.appName('nlp').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- id: string (nullable = true)\n",
      " |-- keyword: string (nullable = true)\n",
      " |-- location: string (nullable = true)\n",
      " |-- text: string (nullable = true)\n",
      " |-- target: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "filepath = \"/media/mnegm/Negmo's Files/Artificial intelligence/Negmo's workspace/Python/Pysparkpro/data\"\n",
    "sdf_train = spark.read.csv(f'{filepath}/train.csv', header = True, inferSchema = True)\n",
    "sdf_test = spark.read.csv(f'{filepath}/test.csv', inferSchema=True, header=True)\n",
    "\n",
    "sdf_sample_submission = spark.read.csv(f'{filepath}/sample_submission.csv', inferSchema=True, header=True)\n",
    "sdf_train.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>All residents asked to 'shelter in place' are ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  id keyword location                                               text  \\\n",
       "0  1    None     None  Our Deeds are the Reason of this #earthquake M...   \n",
       "1  4    None     None             Forest fire near La Ronge Sask. Canada   \n",
       "2  5    None     None  All residents asked to 'shelter in place' are ...   \n",
       "3  6    None     None  13,000 people receive #wildfires evacuation or...   \n",
       "4  7    None     None  Just got sent this photo from Ruby #Alaska as ...   \n",
       "\n",
       "   target  \n",
       "0       1  \n",
       "1       1  \n",
       "2       1  \n",
       "3       1  \n",
       "4       1  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pd.DataFrame(sdf_train.take(5), columns=sdf_train.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data Record Count: 8387\n",
      "Test Data Record Count: 3613\n"
     ]
    }
   ],
   "source": [
    "print(\"Training Data Record Count:\",sdf_train.count())\n",
    "print(\"Test Data Record Count:\",sdf_test.count())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "target\n",
       "0.0    4095\n",
       "1.0    3081\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sdf_train.toPandas().groupby(['target']).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------------------+------+\n",
      "| id|                text|target|\n",
      "+---+--------------------+------+\n",
      "|  1|Our Deeds are the...|     1|\n",
      "|  4|Forest fire near ...|     1|\n",
      "|  5|All residents ask...|     1|\n",
      "|  6|13,000 people rec...|     1|\n",
      "|  7|Just got sent thi...|     1|\n",
      "+---+--------------------+------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ml_df = sdf_train.select(\"id\",\"text\",\"target\")\n",
    "ml_df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7176"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ml_df = ml_df.dropna()\n",
    "ml_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------------------+------+--------------------+\n",
      "| id|                text|target|            only_str|\n",
      "+---+--------------------+------+--------------------+\n",
      "|  1|Our Deeds are the...|     1|Our Deeds are the...|\n",
      "|  4|Forest fire near ...|     1|Forest fire near ...|\n",
      "|  5|All residents ask...|     1|All residents ask...|\n",
      "|  6|13,000 people rec...|     1|, people receive ...|\n",
      "|  7|Just got sent thi...|     1|Just got sent thi...|\n",
      "+---+--------------------+------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ml_df = ml_df.withColumn(\"only_str\",regexp_replace(col('text'), '\\d+', ''))\n",
    "ml_df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------------------+------+--------------------+--------------------+\n",
      "| id|                text|target|            only_str|               words|\n",
      "+---+--------------------+------+--------------------+--------------------+\n",
      "|  1|Our Deeds are the...|     1|Our Deeds are the...|[our, deeds, are,...|\n",
      "|  4|Forest fire near ...|     1|Forest fire near ...|[forest, fire, ne...|\n",
      "|  5|All residents ask...|     1|All residents ask...|[all, residents, ...|\n",
      "|  6|13,000 people rec...|     1|, people receive ...|[people, receive,...|\n",
      "|  7|Just got sent thi...|     1|Just got sent thi...|[just, got, sent,...|\n",
      "+---+--------------------+------+--------------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "regex_tokenizer = RegexTokenizer(inputCol=\"only_str\", outputCol=\"words\", pattern=\"\\\\W\")\n",
    "raw_words = regex_tokenizer.transform(ml_df)\n",
    "raw_words.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---------------------------------------------------------------------------------------------------------------------------------------------------------+------+----------------------------------------------------------------------------------------------------+\n",
      "|id |words                                                                                                                                                    |target|filtered                                                                                            |\n",
      "+---+---------------------------------------------------------------------------------------------------------------------------------------------------------+------+----------------------------------------------------------------------------------------------------+\n",
      "|1  |[our, deeds, are, the, reason, of, this, earthquake, may, allah, forgive, us, all]                                                                       |1     |[deeds, reason, earthquake, may, allah, forgive, us]                                                |\n",
      "|4  |[forest, fire, near, la, ronge, sask, canada]                                                                                                            |1     |[forest, fire, near, la, ronge, sask, canada]                                                       |\n",
      "|5  |[all, residents, asked, to, shelter, in, place, are, being, notified, by, officers, no, other, evacuation, or, shelter, in, place, orders, are, expected]|1     |[residents, asked, shelter, place, notified, officers, evacuation, shelter, place, orders, expected]|\n",
      "|6  |[people, receive, wildfires, evacuation, orders, in, california]                                                                                         |1     |[people, receive, wildfires, evacuation, orders, california]                                        |\n",
      "|7  |[just, got, sent, this, photo, from, ruby, alaska, as, smoke, from, wildfires, pours, into, a, school]                                                   |1     |[got, sent, photo, ruby, alaska, smoke, wildfires, pours, school]                                   |\n",
      "+---+---------------------------------------------------------------------------------------------------------------------------------------------------------+------+----------------------------------------------------------------------------------------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "remover = StopWordsRemover(inputCol=\"words\", outputCol=\"filtered\")\n",
    "words_df = remover.transform(raw_words)\n",
    "words_df.select(\"id\",\"words\",\"target\",\"filtered\").show(5, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------------------+------+--------------------+--------------------+--------------------+--------------------+-----+\n",
      "| id|                text|target|            only_str|               words|            filtered|            features|label|\n",
      "+---+--------------------+------+--------------------+--------------------+--------------------+--------------------+-----+\n",
      "|  1|Our Deeds are the...|     1|Our Deeds are the...|[our, deeds, are,...|[deeds, reason, e...|(19663,[24,65,148...|    1|\n",
      "|  4|Forest fire near ...|     1|Forest fire near ...|[forest, fire, ne...|[forest, fire, ne...|(19663,[7,100,140...|    1|\n",
      "|  5|All residents ask...|     1|All residents ask...|[all, residents, ...|[residents, asked...|(19663,[156,578,9...|    1|\n",
      "|  6|13,000 people rec...|     1|, people receive ...|[people, receive,...|[people, receive,...|(19663,[11,23,156...|    1|\n",
      "|  7|Just got sent thi...|     1|Just got sent thi...|[just, got, sent,...|[got, sent, photo...|(19663,[32,102,15...|    1|\n",
      "+---+--------------------+------+--------------------+--------------------+--------------------+--------------------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cv = CountVectorizer(inputCol=\"filtered\", outputCol=\"features\")\n",
    "model = cv.fit(words_df)\n",
    "countVectorizer_train = model.transform(words_df)\n",
    "countVectorizer_train = countVectorizer_train.withColumn(\"label\",col('target'))\n",
    "countVectorizer_train.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+--------------------+--------------------+------+\n",
      "|                text|               words|            filtered|            features|target|\n",
      "+--------------------+--------------------+--------------------+--------------------+------+\n",
      "|Our Deeds are the...|[our, deeds, are,...|[deeds, reason, e...|(19663,[24,65,148...|     1|\n",
      "|Forest fire near ...|[forest, fire, ne...|[forest, fire, ne...|(19663,[7,100,140...|     1|\n",
      "|All residents ask...|[all, residents, ...|[residents, asked...|(19663,[156,578,9...|     1|\n",
      "|13,000 people rec...|[people, receive,...|[people, receive,...|(19663,[11,23,156...|     1|\n",
      "|Just got sent thi...|[just, got, sent,...|[got, sent, photo...|(19663,[32,102,15...|     1|\n",
      "|#RockyFire Update...|[rockyfire, updat...|[rockyfire, updat...|(19663,[7,23,284,...|     1|\n",
      "|#flood #disaster ...|[flood, disaster,...|[flood, disaster,...|(19663,[17,121,17...|     1|\n",
      "|I'm on top of the...|[i, m, on, top, o...|[m, top, hill, se...|(19663,[6,7,48,12...|     1|\n",
      "|There's an emerge...|[there, s, an, em...|[emergency, evacu...|(19663,[16,156,48...|     1|\n",
      "|I'm afraid that t...|[i, m, afraid, th...|[m, afraid, torna...|(19663,[6,157,164...|     1|\n",
      "|Three people died...|[three, people, d...|[three, people, d...|(19663,[11,183,35...|     1|\n",
      "|Haha South Tampa ...|[haha, south, tam...|[haha, south, tam...|(19663,[119,122,1...|     1|\n",
      "|#raining #floodin...|[raining, floodin...|[raining, floodin...|(19663,[68,172,43...|     1|\n",
      "|#Flood in Bago My...|[flood, in, bago,...|[flood, bago, mya...|(19663,[121,780,1...|     1|\n",
      "|Damage to school ...|[damage, to, scho...|[damage, school, ...|(19663,[25,51,102...|     1|\n",
      "|      What's up man?|  [what, s, up, man]|               [man]|  (19663,[30],[1.0])|     0|\n",
      "|       I love fruits|   [i, love, fruits]|      [love, fruits]|(19663,[52,17939]...|     0|\n",
      "|    Summer is lovely|[summer, is, lovely]|    [summer, lovely]|(19663,[251,1857]...|     0|\n",
      "|   My car is so fast|[my, car, is, so,...|         [car, fast]|(19663,[51,660],[...|     0|\n",
      "|What a goooooooaa...|[what, a, goooooo...|   [goooooooaaaaaal]|(19663,[7685],[1.0])|     0|\n",
      "+--------------------+--------------------+--------------------+--------------------+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "countVectorizer_train.select('text','words','filtered','features','target').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "(train, validate) = countVectorizer_train.randomSplit([0.8, 0.2],seed = 97435)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| id|                text|            only_str|               words|            filtered|            features|\n",
      "+---+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "|  0|Just happened a t...|Just happened a t...|[just, happened, ...|[happened, terrib...|(11358,[32,55,469...|\n",
      "|  2|Heard about #eart...|Heard about #eart...|[heard, about, ea...|[heard, earthquak...|(11358,[181,196,4...|\n",
      "|  3|there is a forest...|there is a forest...|[there, is, a, fo...|[forest, fire, sp...|(11358,[7,54,338,...|\n",
      "|  9|Apocalypse lighti...|Apocalypse lighti...|[apocalypse, ligh...|[apocalypse, ligh...|(11358,[179,1039,...|\n",
      "| 11|Typhoon Soudelor ...|Typhoon Soudelor ...|[typhoon, soudelo...|[typhoon, soudelo...|(11358,[153,201,2...|\n",
      "+---+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "trainData = countVectorizer_train\n",
    "\n",
    "#cleaning and preparing the test data\n",
    "testData = sdf_test.select(\"id\",\"text\").dropna()\n",
    "testData = testData.withColumn(\"only_str\",regexp_replace(col('text'), '\\d+', ''))\n",
    "regex_tokenizer = RegexTokenizer(inputCol=\"only_str\", outputCol=\"words\", pattern=\"\\\\W\")  #Extracting raw words\n",
    "testData = regex_tokenizer.transform(testData)\n",
    "remover = StopWordsRemover(inputCol=\"words\", outputCol=\"filtered\") #Removing stop words\n",
    "testData = remover.transform(testData)\n",
    "cv = CountVectorizer(inputCol=\"filtered\", outputCol=\"features\")\n",
    "model = cv.fit(testData)\n",
    "countVectorizer_test = model.transform(testData)\n",
    "testData = countVectorizer_test\n",
    "testData.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "nb = NaiveBayes(modelType=\"multinomial\",labelCol=\"label\", featuresCol=\"features\")\n",
    "nbModel = nb.fit(train)\n",
    "nb_predictions = nbModel.transform(validate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Area Under ROC 0.4302179682948281\n"
     ]
    }
   ],
   "source": [
    "nbEval = BinaryClassificationEvaluator()\n",
    "print('Test Area Under ROC', nbEval.evaluate(nb_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 44:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of NaiveBayes is = 0.803413\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "evaluator = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "nb_accuracy = evaluator.evaluate(nb_predictions)\n",
    "print(\"Accuracy of NaiveBayes is = %g\"% (nb_accuracy))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "negmo_v_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6 (main, Nov 14 2022, 16:10:14) [GCC 11.3.0]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a8af3121cd7a243bafbea5781b13526e2e472f6b29d453039e506755d5f88381"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
